{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sys import platform\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    # linux\n",
    "    path='/home/vkalbag/projects/'\n",
    "elif platform == \"darwin\":\n",
    "    # OS X\n",
    "    path='/Users/vedant/Desktop/Programming/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['video_id','start_time','mid_ts','label','audio','vggish']\n",
    "\n",
    "d=np.load(f'{path}ScreamDetection/resources/working_data/vocal_only_data_with_vggish.npy',allow_pickle=True)\n",
    "df = pd.DataFrame(d,columns=cols)\n",
    "\n",
    "lut = pd.read_csv(f'{path}/ScreamDetection/resources/dataset/lookup_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>mid_ts</th>\n",
       "      <th>label</th>\n",
       "      <th>audio</th>\n",
       "      <th>vggish</th>\n",
       "      <th>band_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4600fGWcn9o</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>[0.0, 0.0, 0.0, -3.0517578125e-05, -1.52587890...</td>\n",
       "      <td>[166.0, 8.0, 149.0, 128.0, 199.0, 57.0, 96.0, ...</td>\n",
       "      <td>Textures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4600fGWcn9o</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>[0.0004730224609375, 0.0001983642578125, -6.10...</td>\n",
       "      <td>[175.0, 10.0, 147.0, 103.0, 210.0, 74.0, 81.0,...</td>\n",
       "      <td>Textures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4600fGWcn9o</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>[-4.57763671875e-05, -3.0517578125e-05, 1.5258...</td>\n",
       "      <td>[173.0, 10.0, 148.0, 131.0, 191.0, 76.0, 71.0,...</td>\n",
       "      <td>Textures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4600fGWcn9o</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>[3.0517578125e-05, 0.0, -3.0517578125e-05, 0.0...</td>\n",
       "      <td>[164.0, 7.0, 154.0, 128.0, 190.0, 80.0, 29.0, ...</td>\n",
       "      <td>Textures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4600fGWcn9o</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>[-0.0008087158203125, -0.000885009765625, -0.0...</td>\n",
       "      <td>[169.0, 11.0, 146.0, 115.0, 191.0, 75.0, 108.0...</td>\n",
       "      <td>Textures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33815</th>\n",
       "      <td>0m5fIHHfJTw</td>\n",
       "      <td>217.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>[1.52587890625e-05, 6.103515625e-05, 0.0001220...</td>\n",
       "      <td>[174.0, 13.0, 142.0, 130.0, 194.0, 76.0, 84.0,...</td>\n",
       "      <td>Lamb of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33816</th>\n",
       "      <td>0m5fIHHfJTw</td>\n",
       "      <td>218.0</td>\n",
       "      <td>218.5</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>[6.103515625e-05, 9.1552734375e-05, 0.00012207...</td>\n",
       "      <td>[174.0, 10.0, 148.0, 124.0, 190.0, 77.0, 86.0,...</td>\n",
       "      <td>Lamb of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33817</th>\n",
       "      <td>0m5fIHHfJTw</td>\n",
       "      <td>218.5</td>\n",
       "      <td>219.0</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>[0.0, -1.52587890625e-05, -1.52587890625e-05, ...</td>\n",
       "      <td>[171.0, 9.0, 140.0, 110.0, 201.0, 56.0, 68.0, ...</td>\n",
       "      <td>Lamb of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33818</th>\n",
       "      <td>0m5fIHHfJTw</td>\n",
       "      <td>219.0</td>\n",
       "      <td>219.5</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>[-1.52587890625e-05, -1.52587890625e-05, -1.52...</td>\n",
       "      <td>[172.0, 10.0, 141.0, 109.0, 203.0, 56.0, 71.0,...</td>\n",
       "      <td>Lamb of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33819</th>\n",
       "      <td>0m5fIHHfJTw</td>\n",
       "      <td>219.5</td>\n",
       "      <td>220.0</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>[-1.52587890625e-05, -1.52587890625e-05, -1.52...</td>\n",
       "      <td>[175.0, 9.0, 147.0, 98.0, 214.0, 75.0, 78.0, 1...</td>\n",
       "      <td>Lamb of God</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33820 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id start_time mid_ts      label  \\\n",
       "0      4600fGWcn9o        0.0    0.5  no_vocals   \n",
       "1      4600fGWcn9o        0.5    1.0  no_vocals   \n",
       "2      4600fGWcn9o        1.0    1.5  no_vocals   \n",
       "3      4600fGWcn9o        1.5    2.0  no_vocals   \n",
       "4      4600fGWcn9o        2.0    2.5  no_vocals   \n",
       "...            ...        ...    ...        ...   \n",
       "33815  0m5fIHHfJTw      217.5  218.0  no_vocals   \n",
       "33816  0m5fIHHfJTw      218.0  218.5  no_vocals   \n",
       "33817  0m5fIHHfJTw      218.5  219.0  no_vocals   \n",
       "33818  0m5fIHHfJTw      219.0  219.5  no_vocals   \n",
       "33819  0m5fIHHfJTw      219.5  220.0  no_vocals   \n",
       "\n",
       "                                                   audio  \\\n",
       "0      [0.0, 0.0, 0.0, -3.0517578125e-05, -1.52587890...   \n",
       "1      [0.0004730224609375, 0.0001983642578125, -6.10...   \n",
       "2      [-4.57763671875e-05, -3.0517578125e-05, 1.5258...   \n",
       "3      [3.0517578125e-05, 0.0, -3.0517578125e-05, 0.0...   \n",
       "4      [-0.0008087158203125, -0.000885009765625, -0.0...   \n",
       "...                                                  ...   \n",
       "33815  [1.52587890625e-05, 6.103515625e-05, 0.0001220...   \n",
       "33816  [6.103515625e-05, 9.1552734375e-05, 0.00012207...   \n",
       "33817  [0.0, -1.52587890625e-05, -1.52587890625e-05, ...   \n",
       "33818  [-1.52587890625e-05, -1.52587890625e-05, -1.52...   \n",
       "33819  [-1.52587890625e-05, -1.52587890625e-05, -1.52...   \n",
       "\n",
       "                                                  vggish    band_name  \n",
       "0      [166.0, 8.0, 149.0, 128.0, 199.0, 57.0, 96.0, ...     Textures  \n",
       "1      [175.0, 10.0, 147.0, 103.0, 210.0, 74.0, 81.0,...     Textures  \n",
       "2      [173.0, 10.0, 148.0, 131.0, 191.0, 76.0, 71.0,...     Textures  \n",
       "3      [164.0, 7.0, 154.0, 128.0, 190.0, 80.0, 29.0, ...     Textures  \n",
       "4      [169.0, 11.0, 146.0, 115.0, 191.0, 75.0, 108.0...     Textures  \n",
       "...                                                  ...          ...  \n",
       "33815  [174.0, 13.0, 142.0, 130.0, 194.0, 76.0, 84.0,...  Lamb of God  \n",
       "33816  [174.0, 10.0, 148.0, 124.0, 190.0, 77.0, 86.0,...  Lamb of God  \n",
       "33817  [171.0, 9.0, 140.0, 110.0, 201.0, 56.0, 68.0, ...  Lamb of God  \n",
       "33818  [172.0, 10.0, 141.0, 109.0, 203.0, 56.0, 71.0,...  Lamb of God  \n",
       "33819  [175.0, 9.0, 147.0, 98.0, 214.0, 75.0, 78.0, 1...  Lamb of God  \n",
       "\n",
       "[33820 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.merge(lut[['video_id','band_name']],on='video_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df=df[['label','audio','band_name']]\n",
    "mapping=[]\n",
    "for index,row in feature_df.iterrows():\n",
    "    if row['label'] == 'clean':\n",
    "        mapping.append(0)\n",
    "    if row['label'] == 'highfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'layered':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'lowfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'midfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'no_vocals':\n",
    "        mapping.append(2)\n",
    "\n",
    "feature_df.insert(3,'label_mapped',mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling the master data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy={0:2462,1:3000,2:3000},random_state=0)\n",
    "X = feature_df[['audio','band_name']].to_numpy()\n",
    "y=feature_df['label_mapped'].to_numpy()\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "\n",
    "band_names = X_under[:,1]\n",
    "X_under=X_under[:,0]#.reshape(-1,1).flatten()\n",
    "y_under=y_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_under\n",
      "0    2462\n",
      "1    3000\n",
      "2    3000\n",
      "Name: blah, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "d=pd.DataFrame()\n",
    "d['y_under'] = y_under\n",
    "d['blah'] = 1\n",
    "\n",
    "print(d.groupby('y_under')['blah'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train-test-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=5, train_size=.7, random_state=42)\n",
    "train,test = next(gss.split(X_under, y_under, band_names))\n",
    "# for train_idx,test_idx in gss.split(X_under, y_under, band_names): \n",
    "#     print(train_idx,test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_under[train]\n",
    "X_test1 = X_under[test]\n",
    "\n",
    "y_train = y_under[train]\n",
    "y_test1 = y_under[test]\n",
    "\n",
    "X_test,X_valid,y_test,y_valid = train_test_split(X_test1, y_test1,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d=pd.DataFrame(X_train)\n",
    "# d['blah'] = 1\n",
    "# print('TRAIN')\n",
    "# print(d.groupby(1).count())\n",
    "\n",
    "\n",
    "# d=pd.DataFrame(X_test)\n",
    "# d['blah'] = 1\n",
    "# print('TEST')\n",
    "# print(d.groupby(1).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "y_train\n",
      "0    1595\n",
      "1    2057\n",
      "2    2156\n",
      "Name: blah, dtype: int64\n",
      "TEST\n",
      "y_test\n",
      "0    430\n",
      "1    470\n",
      "2    427\n",
      "Name: blah, dtype: int64\n",
      "VALID\n",
      "y_valid\n",
      "0    437\n",
      "1    473\n",
      "2    417\n",
      "Name: blah, dtype: int64\n",
      "Train:Test:Validation - 5808:1327:1327\n"
     ]
    }
   ],
   "source": [
    "d=pd.DataFrame()\n",
    "d['y_train'] = y_train\n",
    "d['blah'] = 1\n",
    "print('TRAIN')\n",
    "print(d.groupby('y_train')['blah'].count())\n",
    "train = d['blah'].sum()\n",
    "\n",
    "d=pd.DataFrame()\n",
    "d['y_test'] = y_test\n",
    "d['blah'] = 1\n",
    "print('TEST')\n",
    "print(d.groupby('y_test')['blah'].count())\n",
    "test = d['blah'].sum()\n",
    "d=pd.DataFrame()\n",
    "d['y_valid'] = y_valid\n",
    "d['blah'] = 1\n",
    "print('VALID')\n",
    "print(d.groupby('y_valid')['blah'].count())\n",
    "valid = d['blah'].sum()\n",
    "\n",
    "print(f\"Train:Test:Validation - {train}:{test}:{valid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "y_train\n",
      "0    1595\n",
      "1    2057\n",
      "2    2156\n",
      "Name: blah, dtype: int64\n",
      "TEST\n",
      "y_test\n",
      "0    430\n",
      "1    470\n",
      "2    427\n",
      "Name: blah, dtype: int64\n",
      "VALID\n",
      "y_valid\n",
      "0    437\n",
      "1    473\n",
      "2    417\n",
      "Name: blah, dtype: int64\n",
      "Train:Test:Validation - 5808:1327:1327\n"
     ]
    }
   ],
   "source": [
    "d=pd.DataFrame()\n",
    "d['y_train'] = y_train\n",
    "d['blah'] = 1\n",
    "print('TRAIN')\n",
    "print(d.groupby('y_train')['blah'].count())\n",
    "train = d['blah'].sum()\n",
    "\n",
    "d=pd.DataFrame()\n",
    "d['y_test'] = y_test\n",
    "d['blah'] = 1\n",
    "print('TEST')\n",
    "print(d.groupby('y_test')['blah'].count())\n",
    "test = d['blah'].sum()\n",
    "d=pd.DataFrame()\n",
    "d['y_valid'] = y_valid\n",
    "d['blah'] = 1\n",
    "print('VALID')\n",
    "print(d.groupby('y_valid')['blah'].count())\n",
    "valid = d['blah'].sum()\n",
    "\n",
    "print(f\"Train:Test:Validation - {train}:{test}:{valid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_valid_hot = to_categorical(y_valid)\n",
    "\n",
    "X_train,y_train=shuffle(X_train,y_train_hot)\n",
    "X_test,y_test=shuffle(X_test,y_test_hot)\n",
    "X_valid,y_valid=shuffle(X_valid,y_valid_hot)\n",
    "\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/x_train-rawaudio.npy', X_train)\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/x_test-rawaudio.npy', X_test)\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/x_valid-rawaudio.npy', X_valid)\n",
    "\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/y_train-rawaudio.npy', y_train)\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/y_test-rawaudio.npy', y_test)\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/y_valid-rawaudio.npy', y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.load(f'{path}ScreamDetection/resources/working_data/vocal_only_data_with_vggish.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33820,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:,5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[166.,   8., 149., ...,  64., 125., 255.],\n",
       "       [175.,  10., 147., ..., 122.,  52., 255.],\n",
       "       [173.,  10., 148., ...,  66.,   0., 255.],\n",
       "       ...,\n",
       "       [171.,   9., 140., ..., 137.,  83., 255.],\n",
       "       [172.,  10., 141., ..., 141.,  63., 255.],\n",
       "       [175.,   9., 147., ..., 150.,  73., 255.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(d[:,5]).reshape(33820,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df=df[['label','vggish','band_name']]\n",
    "mapping=[]\n",
    "for index,row in feature_df.iterrows():\n",
    "    if row['label'] == 'clean':\n",
    "        mapping.append(0)\n",
    "    if row['label'] == 'highfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'layered':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'lowfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'midfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'no_vocals':\n",
    "        mapping.append(2)\n",
    "\n",
    "feature_df.insert(3,'label_mapped',mapping)\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy={0:2462,1:3000,2:3000},random_state=0)\n",
    "X = feature_df[['vggish','band_name']].to_numpy()\n",
    "y=feature_df['label_mapped'].to_numpy()\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "\n",
    "band_names = X_under[:,1]\n",
    "X_under=X_under[:,0]#.reshape(-1,1).flatten()\n",
    "X_under=np.concatenate(X_under).reshape(X_under.shape[0],128)\n",
    "\n",
    "y_under=y_under\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=5, train_size=.7, random_state=42)\n",
    "train,test = next(gss.split(X_under, y_under, band_names))\n",
    "# for train_idx,test_idx in gss.split(X_under, y_under, band_names): \n",
    "#     print(train_idx,test_idx)\n",
    "\n",
    "X_train = X_under[train]\n",
    "X_test1 = X_under[test]\n",
    "\n",
    "y_train = y_under[train]\n",
    "y_test1 = y_under[test]\n",
    "\n",
    "X_test,X_valid,y_test,y_valid = train_test_split(X_test1, y_test1,test_size=0.5,random_state=42)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_valid_hot = to_categorical(y_valid)\n",
    "\n",
    "X_train,y_train=shuffle(X_train,y_train_hot)\n",
    "X_test,y_test=shuffle(X_test,y_test_hot)\n",
    "X_valid,y_valid=shuffle(X_valid,y_valid_hot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/x_train-vggish.npy', X_train)\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/x_test-vggish.npy', X_test)\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/x_valid-vggish.npy', X_valid)\n",
    "\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/y_train-vggish.npy', y_train)\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/y_test-vggish.npy', y_test)\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/y_valid-vggish.npy', y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['video_id', 'start_time', 'mid_ts', 'label', 'average_zcr',\n",
    "       'zcr_stddev', 'mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean',\n",
    "       'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean',\n",
    "       'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean',\n",
    "       'mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std',\n",
    "       'mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std',\n",
    "       'mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std',\n",
    "       'delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean',\n",
    "       'delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean',\n",
    "       'delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean',\n",
    "       'delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean',\n",
    "       'delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std',\n",
    "       'delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std',\n",
    "       'delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std',\n",
    "       'delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std',\n",
    "       'delta_mfcc12_std', 'delta_mfcc13_std',\n",
    "       'centroid_mean','centroid_std',\n",
    "       'contrast_mean','contrast_std',\n",
    "       'flatness_mean','flatness_std',\n",
    "       'rolloff_mean','rolloff_std','rms_mean','rms_std','vggish']\n",
    "\n",
    "d=np.load(f'{path}ScreamDetection/resources/working_data/vocal_only_features.npy',allow_pickle=True)\n",
    "df = pd.DataFrame(d,columns=cols)\n",
    "\n",
    "lut = pd.read_csv(f'{path}/ScreamDetection/resources/dataset/lookup_new.csv')\n",
    "\n",
    "df=df.merge(lut[['video_id','band_name']],on='video_id')\n",
    "df\n",
    "\n",
    "feature_df=df[['label', 'band_name', 'average_zcr',\n",
    "       'zcr_stddev', 'mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean',\n",
    "       'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean',\n",
    "       'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean',\n",
    "       'mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std',\n",
    "       'mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std',\n",
    "       'mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std',\n",
    "       'delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean',\n",
    "       'delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean',\n",
    "       'delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean',\n",
    "       'delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean',\n",
    "       'delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std',\n",
    "       'delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std',\n",
    "       'delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std',\n",
    "       'delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std',\n",
    "       'delta_mfcc12_std', 'delta_mfcc13_std',\n",
    "       'centroid_mean','centroid_std',\n",
    "       'contrast_mean','contrast_std',\n",
    "       'flatness_mean','flatness_std',\n",
    "       'rolloff_mean','rolloff_std','rms_mean','rms_std']]\n",
    "mapping=[]\n",
    "for index,row in feature_df.iterrows():\n",
    "    if row['label'] == 'clean':\n",
    "        mapping.append(0)\n",
    "    if row['label'] == 'highfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'layered':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'lowfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'midfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'no_vocals':\n",
    "        mapping.append(2)\n",
    "\n",
    "feature_df.insert(3,'label_mapped',mapping)\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy={0:2462,1:3000,2:3000},random_state=0)\n",
    "X = feature_df[['average_zcr',\n",
    "       'zcr_stddev', 'mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean',\n",
    "       'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean',\n",
    "       'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean',\n",
    "       'mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std',\n",
    "       'mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std',\n",
    "       'mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std',\n",
    "       'delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean',\n",
    "       'delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean',\n",
    "       'delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean',\n",
    "       'delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean',\n",
    "       'delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std',\n",
    "       'delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std',\n",
    "       'delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std',\n",
    "       'delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std',\n",
    "       'delta_mfcc12_std', 'delta_mfcc13_std',\n",
    "       'centroid_mean','centroid_std',\n",
    "       'contrast_mean','contrast_std',\n",
    "       'flatness_mean','flatness_std',\n",
    "       'rolloff_mean','rolloff_std','rms_mean','rms_std','band_name']].to_numpy()\n",
    "y=feature_df['label_mapped'].to_numpy()\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "\n",
    "band_names = X_under[:,-1]\n",
    "X_under=X_under[:,:-1]#.reshape(-1,1).flatten()\n",
    "y_under=y_under\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=5, train_size=.7, random_state=42)\n",
    "train,test = next(gss.split(X_under, y_under, band_names))\n",
    "# for train_idx,test_idx in gss.split(X_under, y_under, band_names): \n",
    "#     print(train_idx,test_idx)\n",
    "\n",
    "X_train = X_under[train]\n",
    "X_test1 = X_under[test]\n",
    "\n",
    "y_train = y_under[train]\n",
    "y_test1 = y_under[test]\n",
    "\n",
    "X_test,X_valid,y_test,y_valid = train_test_split(X_test1, y_test1,test_size=0.5,random_state=42)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_valid_hot = to_categorical(y_valid)\n",
    "\n",
    "X_train,y_train=shuffle(X_train,y_train_hot)\n",
    "X_test,y_test=shuffle(X_test,y_test_hot)\n",
    "X_valid,y_valid=shuffle(X_valid,y_valid_hot)\n",
    "\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/x_train-features_unnormalized.npy', X_train)\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/x_test-features_unnormalized.npy', X_test)\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/x_valid-features_unnormalized.npy', X_valid)\n",
    "\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/y_train-features_unnormalized.npy', y_train)\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/y_test-features_unnormalized.npy', y_test)\n",
    "np.save(f'{path}ScreamDetection/FINAL/working_data_final/y_valid-features_unnormalized.npy', y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
