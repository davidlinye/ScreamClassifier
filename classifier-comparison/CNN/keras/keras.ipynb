{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.io.wavfile, scipy.signal\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "cols=['video_id','start_time','mid_ts','label','audio','vggish']\n",
    "\n",
    "d=np.load('/Users/vedant/Desktop/Programming/ScreamDetection/resources/working_data/vocal_only_data_with_vggish.npy',allow_pickle=True)\n",
    "df = pd.DataFrame(d,columns=cols)\n",
    "\n",
    "lut = pd.read_csv('/Users/vedant/Desktop/Programming/ScreamDetection/resources/dataset/lookup_new.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df=df[cols]\n",
    "mapping=[]\n",
    "for index,row in feature_df.iterrows():\n",
    "    if row['label'] == 'clean':\n",
    "        mapping.append(0)\n",
    "    if row['label'] == 'highfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'layered':\n",
    "        mapping.append(2)\n",
    "    if row['label'] == 'lowfry':\n",
    "        mapping.append(3)\n",
    "    if row['label'] == 'midfry':\n",
    "        mapping.append(4)\n",
    "    if row['label'] == 'no_vocals':\n",
    "        mapping.append(5)\n",
    "\n",
    "feature_df.insert(4,'label_mapped',mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>mid_ts</th>\n",
       "      <th>label</th>\n",
       "      <th>label_mapped</th>\n",
       "      <th>audio</th>\n",
       "      <th>vggish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4600fGWcn9o</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, -3.0517578125e-05, -1.52587890...</td>\n",
       "      <td>[166.0, 8.0, 149.0, 128.0, 199.0, 57.0, 96.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4600fGWcn9o</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0004730224609375, 0.0001983642578125, -6.10...</td>\n",
       "      <td>[175.0, 10.0, 147.0, 103.0, 210.0, 74.0, 81.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4600fGWcn9o</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>5</td>\n",
       "      <td>[-4.57763671875e-05, -3.0517578125e-05, 1.5258...</td>\n",
       "      <td>[173.0, 10.0, 148.0, 131.0, 191.0, 76.0, 71.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4600fGWcn9o</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>5</td>\n",
       "      <td>[3.0517578125e-05, 0.0, -3.0517578125e-05, 0.0...</td>\n",
       "      <td>[164.0, 7.0, 154.0, 128.0, 190.0, 80.0, 29.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4600fGWcn9o</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.0008087158203125, -0.000885009765625, -0.0...</td>\n",
       "      <td>[169.0, 11.0, 146.0, 115.0, 191.0, 75.0, 108.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33815</th>\n",
       "      <td>0m5fIHHfJTw</td>\n",
       "      <td>217.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.52587890625e-05, 6.103515625e-05, 0.0001220...</td>\n",
       "      <td>[174.0, 13.0, 142.0, 130.0, 194.0, 76.0, 84.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33816</th>\n",
       "      <td>0m5fIHHfJTw</td>\n",
       "      <td>218.0</td>\n",
       "      <td>218.5</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>5</td>\n",
       "      <td>[6.103515625e-05, 9.1552734375e-05, 0.00012207...</td>\n",
       "      <td>[174.0, 10.0, 148.0, 124.0, 190.0, 77.0, 86.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33817</th>\n",
       "      <td>0m5fIHHfJTw</td>\n",
       "      <td>218.5</td>\n",
       "      <td>219.0</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, -1.52587890625e-05, -1.52587890625e-05, ...</td>\n",
       "      <td>[171.0, 9.0, 140.0, 110.0, 201.0, 56.0, 68.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33818</th>\n",
       "      <td>0m5fIHHfJTw</td>\n",
       "      <td>219.0</td>\n",
       "      <td>219.5</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>5</td>\n",
       "      <td>[-1.52587890625e-05, -1.52587890625e-05, -1.52...</td>\n",
       "      <td>[172.0, 10.0, 141.0, 109.0, 203.0, 56.0, 71.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33819</th>\n",
       "      <td>0m5fIHHfJTw</td>\n",
       "      <td>219.5</td>\n",
       "      <td>220.0</td>\n",
       "      <td>no_vocals</td>\n",
       "      <td>5</td>\n",
       "      <td>[-1.52587890625e-05, -1.52587890625e-05, -1.52...</td>\n",
       "      <td>[175.0, 9.0, 147.0, 98.0, 214.0, 75.0, 78.0, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33820 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id start_time mid_ts      label  label_mapped  \\\n",
       "0      4600fGWcn9o        0.0    0.5  no_vocals             5   \n",
       "1      4600fGWcn9o        0.5    1.0  no_vocals             5   \n",
       "2      4600fGWcn9o        1.0    1.5  no_vocals             5   \n",
       "3      4600fGWcn9o        1.5    2.0  no_vocals             5   \n",
       "4      4600fGWcn9o        2.0    2.5  no_vocals             5   \n",
       "...            ...        ...    ...        ...           ...   \n",
       "33815  0m5fIHHfJTw      217.5  218.0  no_vocals             5   \n",
       "33816  0m5fIHHfJTw      218.0  218.5  no_vocals             5   \n",
       "33817  0m5fIHHfJTw      218.5  219.0  no_vocals             5   \n",
       "33818  0m5fIHHfJTw      219.0  219.5  no_vocals             5   \n",
       "33819  0m5fIHHfJTw      219.5  220.0  no_vocals             5   \n",
       "\n",
       "                                                   audio  \\\n",
       "0      [0.0, 0.0, 0.0, -3.0517578125e-05, -1.52587890...   \n",
       "1      [0.0004730224609375, 0.0001983642578125, -6.10...   \n",
       "2      [-4.57763671875e-05, -3.0517578125e-05, 1.5258...   \n",
       "3      [3.0517578125e-05, 0.0, -3.0517578125e-05, 0.0...   \n",
       "4      [-0.0008087158203125, -0.000885009765625, -0.0...   \n",
       "...                                                  ...   \n",
       "33815  [1.52587890625e-05, 6.103515625e-05, 0.0001220...   \n",
       "33816  [6.103515625e-05, 9.1552734375e-05, 0.00012207...   \n",
       "33817  [0.0, -1.52587890625e-05, -1.52587890625e-05, ...   \n",
       "33818  [-1.52587890625e-05, -1.52587890625e-05, -1.52...   \n",
       "33819  [-1.52587890625e-05, -1.52587890625e-05, -1.52...   \n",
       "\n",
       "                                                  vggish  \n",
       "0      [166.0, 8.0, 149.0, 128.0, 199.0, 57.0, 96.0, ...  \n",
       "1      [175.0, 10.0, 147.0, 103.0, 210.0, 74.0, 81.0,...  \n",
       "2      [173.0, 10.0, 148.0, 131.0, 191.0, 76.0, 71.0,...  \n",
       "3      [164.0, 7.0, 154.0, 128.0, 190.0, 80.0, 29.0, ...  \n",
       "4      [169.0, 11.0, 146.0, 115.0, 191.0, 75.0, 108.0...  \n",
       "...                                                  ...  \n",
       "33815  [174.0, 13.0, 142.0, 130.0, 194.0, 76.0, 84.0,...  \n",
       "33816  [174.0, 10.0, 148.0, 124.0, 190.0, 77.0, 86.0,...  \n",
       "33817  [171.0, 9.0, 140.0, 110.0, 201.0, 56.0, 68.0, ...  \n",
       "33818  [172.0, 10.0, 141.0, 109.0, 203.0, 56.0, 71.0,...  \n",
       "33819  [175.0, 9.0, 147.0, 98.0, 214.0, 75.0, 78.0, 1...  \n",
       "\n",
       "[33820 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy='not minority',random_state=0)\n",
    "from collections import Counter\n",
    "X = feature_df[cols].to_numpy()\n",
    "y=feature_df[['label_mapped']].to_numpy()\n",
    "\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "\n",
    "undersampled_data = pd.DataFrame(X_under,columns=cols)\n",
    "undersampled_data['label_mapped'] = y_under\n",
    "#print(undersampled_data)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "train_inds, test_inds = next(GroupShuffleSplit(test_size=.2, n_splits=2, random_state = 0).split(lut, groups=lut['band_name']))\n",
    "\n",
    "train = lut.iloc[train_inds]\n",
    "test = lut.iloc[test_inds]\n",
    "\n",
    "train_ids = train['video_id'].to_numpy()\n",
    "test_ids = test['video_id'].to_numpy()\n",
    "\n",
    "#df_final = df\n",
    "df_final = undersampled_data\n",
    "train = df_final[df_final.video_id.isin(train_ids)]\n",
    "test = df_final[df_final.video_id.isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train['audio'].to_numpy()\n",
    "y_train_hot = to_categorical(train['label_mapped'].to_numpy())\n",
    "\n",
    "x_test = test['audio'].to_numpy()\n",
    "y_test_hot = to_categorical(test['label_mapped'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "for y in x_train:\n",
    "    X_train.append(librosa.feature.melspectrogram(y=y, sr=44100))\n",
    "for y in x_test:\n",
    "    X_test.append(librosa.feature.melspectrogram(y=y, sr=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.67109888e-01, 3.56413117e-01, 3.41168868e-01, 1.64408049e+00,\n",
       "        3.62421605e+00],\n",
       "       [1.89459790e-01, 1.78043458e-01, 1.68788214e-01, 1.98767356e+00,\n",
       "        3.79144133e+00],\n",
       "       [7.20001834e-03, 4.69622717e-03, 1.60461646e-03, 1.97867469e+00,\n",
       "        3.95877778e+00],\n",
       "       ...,\n",
       "       [1.82328636e-02, 8.86772891e-03, 1.40041148e-04, 4.46740574e-03,\n",
       "        8.68626982e-03],\n",
       "       [1.90051444e-02, 9.63314786e-03, 4.09516404e-04, 4.54941867e-03,\n",
       "        8.84801564e-03],\n",
       "       [1.95289571e-02, 9.90402639e-03, 5.63061428e-05, 4.14994282e-03,\n",
       "        8.69031545e-03]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(librosa.stft(y,44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stft = []\n",
    "X_test_stft = []\n",
    "for y in x_train:\n",
    "    X_train_stft.append(np.abs(librosa.stft(y)))\n",
    "for y in x_test:\n",
    "    X_test_stft.append(np.abs(librosa.stft(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2280,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050,)\n",
      "(1050, 1025, 87)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(np.array(X_test_stft).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 87)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_test)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 128, 87, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 128, 87, 1)\n",
    "\n",
    "X_train,y_train=shuffle(X_train,y_train_hot)\n",
    "X_test,y_test=shuffle(X_test,y_test_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stft=np.array(X_train_stft)\n",
    "X_test_stft=np.array(X_test_stft)\n",
    "\n",
    "X_train_stft = X_train_stft.reshape(X_train_stft.shape[0], 1025, 87, 1)\n",
    "X_test_stft = X_test_stft.reshape(X_test_stft.shape[0], 1025, 87, 1)\n",
    "\n",
    "X_train_stft,y_train_stft=shuffle(X_train_stft,y_train_hot)\n",
    "X_test_stft,y_test_stft=shuffle(X_test_stft,y_test_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 1024, 86, 16)      80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 512, 43, 16)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 352256)            0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 6)                 2113542   \n",
      "=================================================================\n",
      "Total params: 2,113,622\n",
      "Trainable params: 2,113,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = (1025,87,1)#(128, 87, 1)\n",
    "model.add(Conv2D(16, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(16, kernel_size=(2, 2), activation='relu', input_shape=(512,43,8)))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mel spectrogram + 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 127, 86, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 63, 43, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 43344)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 6)                 260070    \n",
      "=================================================================\n",
      "Total params: 260,150\n",
      "Trainable params: 260,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 4s 209ms/step - loss: 7.2577 - accuracy: 0.1741 - val_loss: 6.2692 - val_accuracy: 0.1695\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 7.1166 - accuracy: 0.1746 - val_loss: 6.1700 - val_accuracy: 0.1648\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 3s 156ms/step - loss: 7.0004 - accuracy: 0.1772 - val_loss: 6.0839 - val_accuracy: 0.1657\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 6.9004 - accuracy: 0.1776 - val_loss: 6.0085 - val_accuracy: 0.1648\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 3s 175ms/step - loss: 6.8131 - accuracy: 0.1754 - val_loss: 5.9429 - val_accuracy: 0.1657\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 6.7363 - accuracy: 0.1754 - val_loss: 5.8838 - val_accuracy: 0.1667\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 3s 172ms/step - loss: 6.6673 - accuracy: 0.1781 - val_loss: 5.8305 - val_accuracy: 0.1619\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 3s 195ms/step - loss: 6.6049 - accuracy: 0.1768 - val_loss: 5.7824 - val_accuracy: 0.1648\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 6.5478 - accuracy: 0.1781 - val_loss: 5.7378 - val_accuracy: 0.1657\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 6.4952 - accuracy: 0.1785 - val_loss: 5.6966 - val_accuracy: 0.1629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x192696eb0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = (128, 87, 1)\n",
    "model.add(Conv2D(16, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(16, kernel_size=(2, 2), activation='relu', input_shape=(512,43,8)))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "epochs=10\n",
    "batch_size=128\n",
    "# fit the model\n",
    "model.fit(np.array(X_train), y_train_hot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mel Spectrogram + 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 127, 86, 8)        40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 63, 43, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 62, 42, 16)        528       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 31, 21, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 10416)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               1333376   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 1,334,718\n",
      "Trainable params: 1,334,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 4s 187ms/step - loss: 7.0164 - accuracy: 0.1750 - val_loss: 5.9230 - val_accuracy: 0.1495\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 3s 171ms/step - loss: 6.6582 - accuracy: 0.1763 - val_loss: 5.6632 - val_accuracy: 0.1552\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 6.3694 - accuracy: 0.1732 - val_loss: 5.4530 - val_accuracy: 0.1581\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 3s 161ms/step - loss: 6.1267 - accuracy: 0.1750 - val_loss: 5.2807 - val_accuracy: 0.1686\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 3s 157ms/step - loss: 5.9185 - accuracy: 0.1750 - val_loss: 5.1364 - val_accuracy: 0.1848\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 3s 156ms/step - loss: 5.7414 - accuracy: 0.1763 - val_loss: 5.0171 - val_accuracy: 0.1943\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 3s 159ms/step - loss: 5.5913 - accuracy: 0.1763 - val_loss: 4.9203 - val_accuracy: 0.1952\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 3s 169ms/step - loss: 5.4629 - accuracy: 0.1781 - val_loss: 4.8395 - val_accuracy: 0.1952\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 3s 171ms/step - loss: 5.3518 - accuracy: 0.1776 - val_loss: 4.7733 - val_accuracy: 0.1895\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 3s 157ms/step - loss: 5.2540 - accuracy: 0.1772 - val_loss: 4.7163 - val_accuracy: 0.1800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1923451c0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = (128, 87, 1)\n",
    "model.add(Conv2D(8, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, kernel_size=(2, 2), activation='relu', input_shape=(512,43,8)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "epochs=10\n",
    "batch_size=128\n",
    "# fit the model\n",
    "model.fit(np.array(X_train), y_train_hot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STFT + 1 conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 1024, 86, 8)       40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 512, 43, 8)        0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 176128)            0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 6)                 1056774   \n",
      "=================================================================\n",
      "Total params: 1,056,814\n",
      "Trainable params: 1,056,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 16s 799ms/step - loss: 2.3863 - accuracy: 0.1781 - val_loss: 2.3159 - val_accuracy: 0.1724\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 11s 607ms/step - loss: 2.2547 - accuracy: 0.1706 - val_loss: 2.2461 - val_accuracy: 0.1686\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 11s 614ms/step - loss: 2.1885 - accuracy: 0.1732 - val_loss: 2.2060 - val_accuracy: 0.1676\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 11s 598ms/step - loss: 2.1513 - accuracy: 0.1750 - val_loss: 2.1858 - val_accuracy: 0.1581\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 11s 614ms/step - loss: 2.1271 - accuracy: 0.1768 - val_loss: 2.1715 - val_accuracy: 0.1552\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 11s 614ms/step - loss: 2.1085 - accuracy: 0.1737 - val_loss: 2.1630 - val_accuracy: 0.1543\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 11s 609ms/step - loss: 2.0930 - accuracy: 0.1781 - val_loss: 2.1551 - val_accuracy: 0.1505\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 11s 614ms/step - loss: 2.0788 - accuracy: 0.1794 - val_loss: 2.1500 - val_accuracy: 0.1552\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 11s 609ms/step - loss: 2.0655 - accuracy: 0.1803 - val_loss: 2.1440 - val_accuracy: 0.1505\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 10s 582ms/step - loss: 2.0529 - accuracy: 0.1807 - val_loss: 2.1364 - val_accuracy: 0.1514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19249d040>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = (1025,87,1)\n",
    "model.add(Conv2D(8, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(16, kernel_size=(2, 2), activation='relu', input_shape=(512,43,8)))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "epochs=10\n",
    "batch_size=128\n",
    "# fit the model\n",
    "model.fit(np.array(X_train_stft), y_train_hot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_stft, y_test_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STFT + 2 conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 1024, 86, 8)       40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 512, 43, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 511, 42, 16)       528       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 255, 21, 16)       0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 85680)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               10967168  \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 10,968,510\n",
      "Trainable params: 10,968,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 20s 1s/step - loss: 2.8448 - accuracy: 0.1750 - val_loss: 2.7511 - val_accuracy: 0.1467\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 19s 1s/step - loss: 2.4250 - accuracy: 0.1746 - val_loss: 2.4966 - val_accuracy: 0.1495\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 19s 1s/step - loss: 2.2628 - accuracy: 0.1724 - val_loss: 2.3549 - val_accuracy: 0.1562\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 19s 1s/step - loss: 2.1785 - accuracy: 0.1798 - val_loss: 2.2631 - val_accuracy: 0.1514\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 19s 1s/step - loss: 2.1255 - accuracy: 0.1829 - val_loss: 2.2119 - val_accuracy: 0.1533\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 19s 1s/step - loss: 2.0859 - accuracy: 0.1833 - val_loss: 2.1752 - val_accuracy: 0.1533\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 19s 1s/step - loss: 2.0533 - accuracy: 0.1908 - val_loss: 2.1496 - val_accuracy: 0.1524\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 19s 1s/step - loss: 2.0241 - accuracy: 0.1930 - val_loss: 2.1264 - val_accuracy: 0.1514\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 19s 1s/step - loss: 1.9979 - accuracy: 0.1991 - val_loss: 2.1130 - val_accuracy: 0.1533\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 18s 1s/step - loss: 1.9733 - accuracy: 0.2035 - val_loss: 2.0991 - val_accuracy: 0.1514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1925c0400>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = (1025,87,1)\n",
    "model.add(Conv2D(8, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, kernel_size=(2, 2), activation='relu', input_shape=(512,43,8)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "epochs=10\n",
    "batch_size=128\n",
    "# fit the model\n",
    "model.fit(np.array(X_train_stft), y_train_hot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_stft, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
